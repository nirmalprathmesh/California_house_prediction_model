import pandas as pd



import pandas as pd
import numpy as np



data = pd.read_csv('housing2.csv')  # Replace with your actual CSV file path


data["income_cat"]= pd.cut(data["median_income"],bins = [0,1.5,3.0,4.5,6,np.inf],labels = [1,2,3,4,5])


data


# import numpy as np
# def shuffle_and_split(data,test_ratio):
#     np.random.seed(42)
#     shuffled_indices = np.random.permutation(len(data))
#     test_set_size = int(len(data)*test_ratio)
#     test_indices = shuffled_indices[:test_set_size]
#     train_indices = shuffled_indices[test_set_size:]
#     return data.iloc[train_indices],data.iloc[test_indices]


# train , test = shuffle_and_split(data,0.2)


# train.head()


# train.info()


import matplotlib.pyplot as plt
data["income_cat"].value_counts().sort_index().plot.bar(rot=0, grid=True)  
plt.title("Income Categories Distribution") 
plt.xlabel("Income Category")
plt.ylabel("Number of Instances")
plt.show()


from sklearn.model_selection import StratifiedShuffleSplit


split = StratifiedShuffleSplit(n_splits=1,test_size=  0.2 , random_state= 42)


for train_index , test_index in split.split(data,data["income_cat"]):
    strat_train_set = data.loc[train_index]
    strat_test_set = data.loc[test_index]


for x in (strat_train_set,strat_test_set):
    x.drop(["income_cat"],axis = 1, inplace = True)


strat_train_set.head()



housing = strat_train_set.drop(["median_house_value"],axis=1)
housing_labels = strat_train_set["median_house_value"]


from sklearn.impute import SimpleImputer


imputer = SimpleImputer(strategy = "median")


housing_num=housing.select_dtypes(include=[np.number])


imputer.fit(housing_num)


X = imputer.transform(housing_num)


print(X)


X_df = pd.DataFrame(X, columns=housing_num.columns)


X_df.info()


X_df["ocean_proximity"] = housing["ocean_proximity"].values



X_df


# reload dataset OR copy before ordinal encoding
housing = X_df.copy()

housing_cat = housing[["ocean_proximity"]]

onehot = OneHotEncoder(sparse_output=False)
housing_cat_1hot = onehot.fit_transform(housing_cat)

onehot.get_feature_names_out()



housing_cat_df = pd.DataFrame(
    housing_cat_1hot,
    columns=onehot.get_feature_names_out(["ocean_proximity"]),
    index=housing.index
)



housing_prepared = pd.concat(
    [X_df, housing_cat_df],
    axis=1
)



housing_prepared


housing_prepared.info()



from sklearn.preprocessing import StandardScaler

std_scaler = StandardScaler()
housing_scaled = std_scaler.fit_transform(housing_prepared)


housing_scaled=pd.DataFrame(housing_scaled,columns = housing_prepared.columns , index = housing_prepared.index)


housing_scaled



